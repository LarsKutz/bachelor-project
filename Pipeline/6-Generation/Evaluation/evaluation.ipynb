{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'question': 'Wie kann man eine Auskunftspflicht in einer Haushaltsgemeinschaft durchsetzen?',\n",
       "  'eval': {'DNB': 2, 'DNT': 2, 'DFB': 6, 'DFT': 6, 'DCB': 2, 'DCT': 4}},\n",
       " {'id': 1,\n",
       "  'question': 'Muss man Schülereinkommen aus Ferienjobs anzurechnen? Wenn ja, in welcher Höhe?',\n",
       "  'eval': {'DNT': 2, 'DFB': 5, 'DFT': 6, 'DCT': 4, 'DNB': 4, 'DCB': 6}},\n",
       " {'id': 2,\n",
       "  'question': 'Wie ist weiter vorzugehen, wenn nach einer Versagung die Mitwirkung nachgeholt wird?',\n",
       "  'eval': {'DFT': 5, 'DCB': 2, 'DCT': 2, 'DNB': 2, 'DNT': 2, 'DFB': 3}},\n",
       " {'id': 3,\n",
       "  'question': 'Wie bemisst sich die Fahrkostenentschädigung bei Teilnahme an einer Maßnahme zur Förderung der beruflichen Weiterbildung?',\n",
       "  'eval': {'DCB': 3, 'DCT': 2, 'DNB': 5, 'DNT': 4, 'DFB': 5, 'DFT': 6}},\n",
       " {'id': 4,\n",
       "  'question': 'Ein Arbeitgeber beantragt einen Zuschuss zur Ausbildungsvergütung. Kann ein derartiger Zuschuss gewährt werden? Wenn ja, unter welchen Voraussetzungen?',\n",
       "  'eval': {'DNT': 5, 'DFB': 4, 'DFT': 3, 'DCT': 4, 'DNB': 5, 'DCB': 6}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_answers_eval_seed_1 = json.load(open(\"seed_1_llm_answers_eval.json\", encoding=\"utf-8\"))\n",
    "llm_answers_eval_seed_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_avg_seed_1 = defaultdict(int)\n",
    "for answer in llm_answers_eval_seed_1:\n",
    "    for val, key in answer['eval'].items():\n",
    "        dict_avg_seed_1[val] += key\n",
    "\n",
    "for val in dict_avg_seed_1:\n",
    "    dict_avg_seed_1[val] /= len(llm_answers_eval_seed_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_27056_row0_col1 {\n",
       "  background-color: darkgreen;\n",
       "}\n",
       "#T_27056_row0_col3 {\n",
       "  background-color: darkred;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_27056\">\n",
       "  <caption>Average evaluation of LLM answers Seed 1</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27056_level0_col0\" class=\"col_heading level0 col0\" >DNB</th>\n",
       "      <th id=\"T_27056_level0_col1\" class=\"col_heading level0 col1\" >DNT</th>\n",
       "      <th id=\"T_27056_level0_col2\" class=\"col_heading level0 col2\" >DFB</th>\n",
       "      <th id=\"T_27056_level0_col3\" class=\"col_heading level0 col3\" >DFT</th>\n",
       "      <th id=\"T_27056_level0_col4\" class=\"col_heading level0 col4\" >DCB</th>\n",
       "      <th id=\"T_27056_level0_col5\" class=\"col_heading level0 col5\" >DCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27056_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n",
       "      <td id=\"T_27056_row0_col0\" class=\"data row0 col0\" >3.6</td>\n",
       "      <td id=\"T_27056_row0_col1\" class=\"data row0 col1\" >3.0</td>\n",
       "      <td id=\"T_27056_row0_col2\" class=\"data row0 col2\" >4.6</td>\n",
       "      <td id=\"T_27056_row0_col3\" class=\"data row0 col3\" >5.2</td>\n",
       "      <td id=\"T_27056_row0_col4\" class=\"data row0 col4\" >3.8</td>\n",
       "      <td id=\"T_27056_row0_col5\" class=\"data row0 col5\" >3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x262e968f610>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seed_1 = pd.DataFrame.from_dict(dict_avg_seed_1, orient='index', columns=['Average']).T\n",
    "df_seed_1 = df_seed_1.style.highlight_max(color='darkred', axis=1).highlight_min(color='darkgreen', axis=1)\n",
    "df_seed_1 = df_seed_1.format(\"{:.1f}\")\n",
    "df_seed_1 = df_seed_1.set_caption('Average evaluation of LLM answers Seed 1')\n",
    "df_seed_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'question': 'Ist es möglich, die Höhe einer russischen Rente umgerechnet in Euro zu erfahren?',\n",
       "  'eval': {'DNB': 1, 'DNT': 1, 'DCT': 1, 'MQNB': 1, 'MQNT': 1, 'MQCT': 1}},\n",
       " {'id': 1,\n",
       "  'question': 'Unter welchen Voraussetzungen ist ein Stromguthaben (Haushaltsstrom) als Einkommen im Sinne des § 11 SGB II bedarfsmindernd zu berücksichtigen?',\n",
       "  'eval': {'MQCT': 1, 'DNB': 1, 'DNT': 1, 'MQNB': 1, 'MQNT': 1, 'DCT': 1}},\n",
       " {'id': 2,\n",
       "  'question': 'Der 29jährige Markus absolviert seinen Bundesfreiwilligendienst und erhält dafür ein Taschengeld i.H.v. 420 €. Er erhält außerdem Mittagsverpflegung als Sachleistung. Diese hat einen Wert von 90 € monatlich. Daneben erzielt er ein Einkommen aus Erwerbstätigkeit von 800 € (brutto= netto). Welche Einkommen sind in welcher Höhe als Einkommen im Sinne des SGB II anzurechnen?',\n",
       "  'eval': {'MQNT': 2, 'MQCT': 6, 'DNT': 1, 'DCT': 6, 'DNB': 1, 'MQNB': 6}},\n",
       " {'id': 3,\n",
       "  'question': 'Die Ehefrau eines aus Syrien geflüchteten Mannes kommt im Rahmen des Familiennachzuges nach Deutschland. Unter welchen Voraussetzungen ist sie zur Ausübung einer Erwerbstätigkeit berechtigt?',\n",
       "  'eval': {'MQCT': 6, 'MQNB': 6, 'DNT': 2, 'DCT': 2, 'DNB': 2, 'MQNT': 6}},\n",
       " {'id': 4,\n",
       "  'question': 'Was passiert, wenn jemand, der an einer Maßnahme zur Wiedereingliederung teilnimmt, seiner Corona-Testverpflichtung nicht nachkommt?',\n",
       "  'eval': {'DCT': 3, 'MQNT': 2, 'MQCT': 3, 'DNB': 5, 'MQNB': 3, 'DNT': 2}},\n",
       " {'id': 5,\n",
       "  'question': 'Ein Antragsteller verweigert die Angabe von Konten und damit die Überprüfung von Einnahmen. Verfügt das Jobcenter über Möglichkeiten, Konten des Leistungsempfängers in Erfahrung zu bringen und wie ist vorzugehen?',\n",
       "  'eval': {'DNB': 1, 'MQNT': 3, 'DCT': 2, 'MQCT': 2, 'DNT': 3, 'MQNB': 4}},\n",
       " {'id': 6,\n",
       "  'question': 'Können Hilfeempfängern im Rahmen der Aufnahme einer sozialversicherungspflichtigen Beschäftigung ggfs. Fahrzeuge zur Verfügung gestellt werden, um den Arbeitsplatz zu erreichen? Fall ja, für welchen Zeitraum ist dies möglich?',\n",
       "  'eval': {'MQCT': 3, 'MQNB': 2, 'DNT': 2, 'DCT': 3, 'MQNT': 3, 'DNB': 1}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_answers_eval_seed_2 = json.load(open(\"seed_2_llm_answers_eval.json\", encoding=\"utf-8\"))\n",
    "llm_answers_eval_seed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_avg_seed_2 = defaultdict(int)\n",
    "for answer in llm_answers_eval_seed_2:\n",
    "    for val, key in answer['eval'].items():\n",
    "        dict_avg_seed_2[val] += key\n",
    "\n",
    "for val in dict_avg_seed_2:\n",
    "    dict_avg_seed_2[val] /= len(llm_answers_eval_seed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e425a_row0_col0, #T_e425a_row0_col1 {\n",
       "  background-color: darkgreen;\n",
       "}\n",
       "#T_e425a_row0_col3 {\n",
       "  background-color: darkred;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e425a\">\n",
       "  <caption>Average evaluation of LLM answers Seed 2</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e425a_level0_col0\" class=\"col_heading level0 col0\" >DNB</th>\n",
       "      <th id=\"T_e425a_level0_col1\" class=\"col_heading level0 col1\" >DNT</th>\n",
       "      <th id=\"T_e425a_level0_col2\" class=\"col_heading level0 col2\" >DCT</th>\n",
       "      <th id=\"T_e425a_level0_col3\" class=\"col_heading level0 col3\" >MQNB</th>\n",
       "      <th id=\"T_e425a_level0_col4\" class=\"col_heading level0 col4\" >MQNT</th>\n",
       "      <th id=\"T_e425a_level0_col5\" class=\"col_heading level0 col5\" >MQCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e425a_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n",
       "      <td id=\"T_e425a_row0_col0\" class=\"data row0 col0\" >1.7</td>\n",
       "      <td id=\"T_e425a_row0_col1\" class=\"data row0 col1\" >1.7</td>\n",
       "      <td id=\"T_e425a_row0_col2\" class=\"data row0 col2\" >2.6</td>\n",
       "      <td id=\"T_e425a_row0_col3\" class=\"data row0 col3\" >3.3</td>\n",
       "      <td id=\"T_e425a_row0_col4\" class=\"data row0 col4\" >2.6</td>\n",
       "      <td id=\"T_e425a_row0_col5\" class=\"data row0 col5\" >3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x262e8190110>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seed_2 = pd.DataFrame.from_dict(dict_avg_seed_2, orient='index', columns=['Average']).T\n",
    "df_seed_2 = df_seed_2.style.highlight_max(color='darkred', axis=1).highlight_min(color='darkgreen', axis=1)\n",
    "df_seed_2 = df_seed_2.format(\"{:.1f}\")\n",
    "df_seed_2 = df_seed_2.set_caption('Average evaluation of LLM answers Seed 2')\n",
    "df_seed_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'DNB': 1.7142857142857142,\n",
       "             'DNT': 1.7142857142857142,\n",
       "             'DCT': 2.5714285714285716,\n",
       "             'MQNB': 3.2857142857142856,\n",
       "             'MQNT': 2.5714285714285716,\n",
       "             'MQCT': 3.142857142857143})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_avg_seed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_average(\n",
    "        avg_1: float | int, \n",
    "        avg_2: float | int, \n",
    "        n_1: int=len(llm_answers_eval_seed_1), \n",
    "        n_2: int=len(llm_answers_eval_seed_2), \n",
    "        round_to: int=None\n",
    "    ):\n",
    "    if not round_to:\n",
    "        return ((avg_1*n_1)+(avg_2*n_2))/(n_1+n_2)\n",
    "    return round(((avg_1*n_1)+(avg_2*n_2))/(n_1+n_2), round_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all = defaultdict(dict)\n",
    "dict_avg = defaultdict(dict)\n",
    "\n",
    "for k1, v1 in dict_avg_seed_1.items():\n",
    "    if dict_avg_seed_2.get(k1):\n",
    "        dict_avg[k1] = calculate_weighted_average(v1, dict_avg_seed_2[k1], round_to=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'DNB': 2.5, 'DNT': 2.2, 'DCT': 2.8})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average over the Retriever types that were used in both seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_20f06_row0_col1 {\n",
       "  background-color: darkgreen;\n",
       "}\n",
       "#T_20f06_row0_col2 {\n",
       "  background-color: darkred;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_20f06\">\n",
       "  <caption>Average evaluation of LLM answers</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_20f06_level0_col0\" class=\"col_heading level0 col0\" >DNB</th>\n",
       "      <th id=\"T_20f06_level0_col1\" class=\"col_heading level0 col1\" >DNT</th>\n",
       "      <th id=\"T_20f06_level0_col2\" class=\"col_heading level0 col2\" >DCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_20f06_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n",
       "      <td id=\"T_20f06_row0_col0\" class=\"data row0 col0\" >2.5</td>\n",
       "      <td id=\"T_20f06_row0_col1\" class=\"data row0 col1\" >2.2</td>\n",
       "      <td id=\"T_20f06_row0_col2\" class=\"data row0 col2\" >2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x262e8181e10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.DataFrame.from_dict(dict_avg, orient='index', columns=['Average']).T\n",
    "df_all = df_all.style.highlight_max(color='darkred', axis=1).highlight_min(color='darkgreen', axis=1)\n",
    "df_all = df_all.format(\"{:.1f}\")\n",
    "ddf_allf = df_all.set_caption('Average evaluation of LLM answers')\n",
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project-KdxDjv4v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
