{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = \"../../Database/\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "CHUNK_SIZE = 1800\n",
    "CHUNKING_LIBRARY = \"Unstructured\"                                       # \"RCTS\" only contains 17 files, \"Unstructured\" contains 108 files\n",
    "METHOD = \"by_title\" if CHUNKING_LIBRARY == \"Unstructured\" else \"\"       # \"by_title\" or \"basic\" - only relevant for Unstructured\n",
    "\n",
    "\n",
    "path_to_db = os.path.join(DATABASE_PATH, f\"{CHUNKING_LIBRARY}\", f\"{METHOD}\", f\"{EMBEDDING_MODEL}\")\n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(\n",
    "    path=path_to_db,\n",
    ")\n",
    "\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=f\"collection_{CHUNK_SIZE}\",\n",
    "    embedding_function=OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=EMBEDDING_MODEL),\n",
    "    client=client,\n",
    "    create_collection_if_not_exists=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_output(text: str, words_per_line: int = 10) -> str:\n",
    "    \"\"\" Prettier output for the text with a given number of words per line.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to be formatted.\n",
    "        words_per_line (int, optional): Number of words per line. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted text.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    split_text = text.split(\" \")\n",
    "\n",
    "    text = \"\"\n",
    "    for i, word in enumerate(split_text, 1):\n",
    "        text += word + \" \"\n",
    "        if i % words_per_line == 0:\n",
    "            text += \"\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"Nach welchen Paragraph kann ich Leistungen ablehnen, wenn Unterlagen fehlen?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An simple retriever that returns the top k documents based on the cosine similarity between the query and the documents.\n",
    "\n",
    "Watch [here](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .as_retriever() method to get the retriever object\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "chunks = retriever.invoke(QUERY)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(\"-\" * 250)\n",
    "    print(pretty_output(chunk.page_content, 20))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using the .similarity_search() method to get the chunks\n",
    "\n",
    "# chunks = vectorstore.similarity_search(\n",
    "#     query=QUESTION,\n",
    "#     k=5,\n",
    "# )\n",
    "\n",
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, chunk in enumerate(chunks):\n",
    "#     print(f\"Chunk {i+1}:\")\n",
    "#     print(\"-\" * 250)\n",
    "#     print(pretty_output(chunk.page_content, 20))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Query Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die abstandsbasierte Abfrage von Vektordatenbanken bettet Abfragen in den hochdimensionalen Raum ein (stellt sie dar) und findet ähnliche eingebettete Dokumente auf der Grundlage einer Abstandsmetrik. Die Abfrage kann jedoch zu unterschiedlichen Ergebnissen führen, wenn sich der Wortlaut der Abfrage geringfügig ändert oder wenn die Einbettung die Semantik der Daten nicht gut erfasst. Um diese Probleme manuell zu beheben, wird manchmal ein Prompt-Engineering/-Tuning durchgeführt, was jedoch sehr mühsam sein kann.\n",
    "\n",
    "Der MultiQueryRetriever automatisiert den Prozess der Promptabstimmung, indem er einen LLM verwendet, um mehrere Abfragen aus verschiedenen Perspektiven für eine gegebene Benutzereingabe zu generieren. Für jede Abfrage wird ein Satz relevanter Dokumente abgerufen und die eindeutige Vereinigung aller Abfragen genommen, um einen größeren Satz potenziell relevanter Dokumente zu erhalten. Durch die Generierung mehrerer Perspektiven auf dieselbe Frage kann der MultiQueryRetriever einige der Beschränkungen der abstandsbasierten Suche abmildern und eine reichhaltigere Menge an Ergebnissen erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch [here](https://python.langchain.com/v0.2/docs/how_to/MultiQueryRetriever/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.from_llm` is using following prompt to generate 3 different queries for the same question.\n",
    "\n",
    "```python\n",
    "DEFAULT_QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is \n",
    "    to generate 3 different versions of the given user \n",
    "    question to retrieve relevant documents from a vector  database. \n",
    "    By generating multiple perspectives on the user question, \n",
    "    your goal is to help the user overcome some of the limitations \n",
    "    of distance-based similarity search. Provide these alternative \n",
    "    questions separated by newlines. Original question: {question}\"\"\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Without Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # to avoid randomness\n",
    ")\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Kann ein Arbeitgeber einen Zuschuss zur Ausbildungsvergütung beantragen, und wenn ja, welche Bedingungen müssen dafür erfüllt sein?  ', 'Welche Voraussetzungen müssen erfüllt sein, damit ein Arbeitgeber einen Zuschuss zur Ausbildungsvergütung erhalten kann?  ', 'Gibt es die Möglichkeit, dass ein Arbeitgeber einen Zuschuss zur Ausbildungsvergütung erhält, und welche Kriterien sind dafür entscheidend?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.invoke(QUERY)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving as Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all this stuff is happening inside of `.from_llm` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Output parser for a list of lines.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))  # Remove empty lines\n",
    "\n",
    "\n",
    "output_parser = LineListOutputParser()\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # to avoid randomness\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm_chain = QUERY_PROMPT | llm | output_parser\n",
    "\n",
    "# Other inputs\n",
    "question = \"What are the approaches to Task Decomposition?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Welche Voraussetzungen müssen erfüllt sein, damit ein Arbeitgeber einen Zuschuss zur Ausbildungsvergütung erhalten kann?', '2. Ist es möglich, dass ein Arbeitgeber einen Zuschuss zur Ausbildungsvergütung beantragt, und wenn ja, welche Bedingungen müssen dafür gelten?', '3. Unter welchen Bedingungen kann ein Zuschuss zur Ausbildungsvergütung für Arbeitgeber gewährt werden?', '4. Gibt es spezielle Richtlinien oder Voraussetzungen, die ein Arbeitgeber beachten muss, um einen Zuschuss zur Ausbildungsvergütung zu beantragen?', '5. Welche Kriterien müssen erfüllt sein, damit ein Zuschuss zur Ausbildungsvergütung für einen Arbeitgeber genehmigt wird?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run\n",
    "retriever = MultiQueryRetriever(\n",
    "    retriever=vectorstore.as_retriever(), \n",
    "    llm_chain=llm_chain, \n",
    "    parser_key=\"lines\"  # \"lines\" is the key (attribute name) of the parsed output\n",
    ")  \n",
    "\n",
    "# Results\n",
    "unique_docs = retriever.invoke(QUERY)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Compression Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Herausforderung bei der Abfrage besteht darin, dass Sie in der Regel nicht wissen, mit welchen spezifischen Abfragen Ihr Dokumentenspeichersystem konfrontiert wird, wenn Sie Daten in das System einspeisen. Das bedeutet, dass die für eine Abfrage wichtigsten Informationen möglicherweise in einem Dokument mit einer Menge irrelevantem Text vergraben sind. Die Weiterleitung des gesamten Dokuments durch Ihre Anwendung kann zu teureren LLM-Aufrufen und schlechteren Antworten führen.\n",
    "\n",
    "Die kontextuelle Komprimierung soll hier Abhilfe schaffen. Die Idee ist einfach: Anstatt die abgerufenen Dokumente sofort unverändert zurückzugeben, können Sie sie unter Verwendung des Kontexts der gegebenen Anfrage komprimieren, so dass nur die relevanten Informationen zurückgegeben werden. „Komprimieren“ bezieht sich hier sowohl auf die Komprimierung des Inhalts eines einzelnen Dokuments als auch auf das Herausfiltern von Dokumenten im Ganzen.\n",
    "\n",
    "Um den Contextual Compression Retriever zu verwenden, benötigen Sie:\n",
    "- einen Basis-Retriever\n",
    "- einen Dokumentenkompressor\n",
    "\n",
    "Der Contextual Compression Retriever übergibt Abfragen an den Basis-Retriever, nimmt die Ausgangsdokumente und leitet sie durch den Document Compressor. Der Document Compressor nimmt eine Liste von Dokumenten und kürzt sie, indem er den Inhalt von Dokumenten reduziert oder Dokumente ganz weglässt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch [here](https://python.langchain.com/v0.2/docs/how_to/contextual_compression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch [here](https://python.langchain.com/v0.2/docs/how_to/parent_document_retriever/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project-KdxDjv4v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
